{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('Software.json',lines=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>This book was missing pages!!! Important pages...</td>\n",
       "      <td>missing pages!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>I'm about 3/4 through this course.  I have bee...</td>\n",
       "      <td>Pretty good but some shortcomings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>Its average prefer Laura Shoe's DVD. The instr...</td>\n",
       "      <td>LR3 DVD review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>I was somewhat disappointed ... I'd read that ...</td>\n",
       "      <td>I must be lacking a core</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>only problem, daughter lost a code and ow cann...</td>\n",
       "      <td>Three Stars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     overall  verified                                         reviewText  \\\n",
       "3          3      True  This book was missing pages!!! Important pages...   \n",
       "31         3      True  I'm about 3/4 through this course.  I have bee...   \n",
       "50         3      True  Its average prefer Laura Shoe's DVD. The instr...   \n",
       "77         3      True  I was somewhat disappointed ... I'd read that ...   \n",
       "103        3      True  only problem, daughter lost a code and ow cann...   \n",
       "\n",
       "                               summary  \n",
       "3                      missing pages!!  \n",
       "31   Pretty good but some shortcomings  \n",
       "50                      LR3 DVD review  \n",
       "77            I must be lacking a core  \n",
       "103                        Three Stars  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns = ['reviewTime','reviewerID','asin','style','reviewerName','unixReviewTime','image','vote'])\n",
    "df = df[df['verified'] == True]\n",
    "df.head()\n",
    "df[df['overall']==3].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall verified reviewText summary\n",
       "0      NaN      NaN        NaN     NaN\n",
       "1      NaN      NaN        NaN     NaN\n",
       "2      NaN      NaN        NaN     NaN\n",
       "3      NaN      NaN        NaN     NaN\n",
       "5      NaN      NaN        NaN     NaN"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    df[df['overall'] == i+1] = df[df['overall'] == i+1].sample(3000)\n",
    "\n",
    "df.loc[df[df['overall']==2].index, 'overall'] = 1\n",
    "df.loc[df[df['overall']==4].index, 'overall'] = 5\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Not worth the price. Most of the concepts are ...</td>\n",
       "      <td>Very simplistic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>only problem, daughter lost a code and ow cann...</td>\n",
       "      <td>Three Stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>My daughter got it and she likes it. She is le...</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>good for learning all aspects of microsoft word</td>\n",
       "      <td>Good Book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>CD not needed for this class-all info was prov...</td>\n",
       "      <td>Five Stars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     overall verified                                         reviewText  \\\n",
       "12       1.0     True  Not worth the price. Most of the concepts are ...   \n",
       "103      3.0     True  only problem, daughter lost a code and ow cann...   \n",
       "120      5.0     True  My daughter got it and she likes it. She is le...   \n",
       "222      5.0     True    good for learning all aspects of microsoft word   \n",
       "224      5.0     True  CD not needed for this class-all info was prov...   \n",
       "\n",
       "             summary  \n",
       "12   Very simplistic  \n",
       "103      Three Stars  \n",
       "120             Good  \n",
       "222        Good Book  \n",
       "224       Five Stars  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data= df.dropna(subset=['reviewText'])\n",
    "data= df.dropna(subset=['summary'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400961                                  HARDLY A NIGHTS DAY\n",
       "11176                                         reader rabbit\n",
       "93558              One computer Download was Disappointment\n",
       "250997                                           Four Stars\n",
       "250627    I've been a user for many years and have been ...\n",
       "Name: summary, dtype: object"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['summary'], data['overall'], test_size = 0.3, random_state=0, shuffle= True, stratify=data['overall'])\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of Word Approach "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline([('tfidf',TfidfVectorizer()), ('clf', RandomForestClassifier(n_estimators= 150,n_jobs=-1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "print(888)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1463,  123,  214],\n",
       "       [ 388,  299,  213],\n",
       "       [ 275,   97, 1428]], dtype=int64)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.69      0.81      0.75      1800\n",
      "         3.0       0.58      0.33      0.42       900\n",
      "         5.0       0.77      0.79      0.78      1800\n",
      "\n",
      "    accuracy                           0.71      4500\n",
      "   macro avg       0.68      0.65      0.65      4500\n",
      "weighted avg       0.70      0.71      0.69      4500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    token = []\n",
    "    for token in  doc:\n",
    "        if token.lemma_!= \"-PRON-\":\n",
    "            temp = token.lemma_.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "So do you like Photoshop 7?  Yeah... This is NOTHING like that."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = X_train[439017]\n",
    "doc = nlp(text)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = list(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So so\n",
      "do do\n",
      "you -PRON-\n",
      "like like\n",
      "Photoshop Photoshop\n",
      "7 7\n",
      "? ?\n",
      "   \n",
      "Yeah yeah\n",
      "... ...\n",
      "This this\n",
      "is be\n",
      "NOTHING nothing\n",
      "like like\n",
      "that that\n",
      ". .\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp('run runs running runner')\n",
    "for lem in doc:\n",
    "    print(lem.text, lem.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
